{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018/5/30\n",
    "\n",
    "Background Removal with Robust PCA\n",
    "\n",
    "[Unit 3 Lecture 4](https://www.youtube.com/watch?v=Ys8R2nUTOAk&index=4&list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD:\n",
    "\n",
    "- Singular Value Decomposition: 1st matrix of orthonormal columns, 2nd a diagonal matrix with singular values in descending order, and 3rd a matrix of orthonormal rows.\n",
    "\n",
    "Randomized SVD:\n",
    "\n",
    "- Trying to get truncated form much faster. Full SVD: able to fully reconstruct data matrix. May be useful, but unnecessary & pot.harmful for data-compression or focus on speed. Quicker to not calculate everything.\n",
    "\n",
    "Full SVD is slow. Randomized SVD much faster (pot.by an order of magnitude).\n",
    "\n",
    "SVD runtime complexity: O(*min*(m$^2$n, mn$^2$))\n",
    "\n",
    "Instead of calculating SVD on full matrix A (size: (m,n)), use B = AQ of size (m,r) where r << n.\n",
    "\n",
    "We end up using the same `scipy` implementation of SVD, but we just multiply our matrix by a random one to make it smaller. B is a low-rank approximation of A, given that it needs to have the same or similar column space to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (FastAI)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
