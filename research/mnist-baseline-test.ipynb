{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018/5/19-20\n",
    "\n",
    "Making sure I have a working baseline for the MNIST dataset. PyTorch version: `0.3.1.post2`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import struct   # for IDX conversion\n",
    "import gzip     # for IDX conversion\n",
    "from urllib.request import urlretrieve # for IDX conversion\n",
    "\n",
    "from fastai.conv_learner import * # if you want to use fastai Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "sz = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic method for creating a DataLoader in PyTorch. Adapted from [their tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=mnist#) and an older [notebook](https://github.com/WNoxchi/Kaukasos/blob/master/PyTorch/practice-mnist.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision datasets are PIL.Image images of range [0,1]. Must trsfm them \n",
    "# to Tensors of normalized range [-1,1]\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see: https://gist.github.com/kevinzakka/d33bf8d6c7f06a9d8c76d97a7879f5cb\n",
    "# frm: https://github.com/pytorch/pytorch/issues/1106\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=PATH, train=True, download=True,\n",
    "                                   transform=transform)\n",
    "validset = torchvision.datasets.MNIST(root=PATH, train=True, download=True,\n",
    "                                   transform=transform)\n",
    "testset  = torchvision.datasets.MNIST(root=PATH, train=True, download=True,\n",
    "                                   transform=transform)\n",
    "p_val = 0.15\n",
    "n_val = int(p_val * len(trainset))\n",
    "idxs  = np.arange(len(trainset))\n",
    "np.random.shuffle(idxs)\n",
    "train_idxs, valid_idxs = idxs[n_val:], idxs[:n_val]\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_idxs)\n",
    "valid_sampler = torch.utils.data.sampler.SequentialSampler(valid_idxs)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs,\n",
    "                                          sampler=train_sampler, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=bs,\n",
    "                                          sampler=valid_sampler, num_workers=2)\n",
    "testloader  = torch.utils.data.DataLoader(testset, batch_size=bs, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [str(i) for i in range(10)]; classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside: DataLoaders – PyTorch & fastai:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FastAI DataLoader shares some similarities in construction with the PyTorch one. The logic defining pytorch's DataLoader [in the PyTorch source code](https://pytorch.org/docs/master/_modules/torch/utils/data/dataloader.html#DataLoader):\n",
    "```\n",
    "if batch_sampler is None:\n",
    "    if sampler is None:\n",
    "        if shuffle:\n",
    "            sampler = RandomSampler(dataset)\n",
    "        else:\n",
    "            sampler = SequentialSampler(dataset)\n",
    "    batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n",
    "```\n",
    "is the same as [that in fast.ai's](https://github.com/fastai/fastai/blob/master/fastai/dataloader.py#L24-43)\n",
    "\n",
    "```\n",
    "if batch_sampler is None:\n",
    "    if sampler is None:\n",
    "        sampler = RandomSampler(dataset) if shuffle else SequentialSampler(dataset)\n",
    "    batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n",
    "```\n",
    "\n",
    "So now I'm not confused about not using a batch sampler when building a pytorch dataloader, although I see one in fastai's DataLoader –– that's because pytorch does it too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Method (for Fast AI Model Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads and converts the MNIST IDX files into NumPy arrays. For MNIST data this looks to be about 45 MB for the images. This way allows for easy use of FastAI's ModelData class, and thus its (extremely useful) Learner abstraction and all other capabilities that come with it. The arrays can be loaded via: `ImageClassifierData.from_arrays(..)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist(path=Path('data/mnist')):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    urls = ['http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "            'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "            'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "            'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',]\n",
    "    for url in urls:\n",
    "        fname = url.split('/')[-1]\n",
    "        if not os.path.exists(path/fname): urlretrieve(url, path/fname)\n",
    "\n",
    "def read_IDX(fname):\n",
    "    \"\"\"see: https://gist.github.com/tylerneylon/ce60e8a06e7506ac45788443f7269e40\"\"\"\n",
    "    with gzip.open(fname) as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t10k-images-idx3-ubyte.gz',\n",
       " 'train-images-idx3-ubyte.gz',\n",
       " 'train-labels-idx1-ubyte.gz',\n",
       " 't10k-labels-idx1-ubyte.gz']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = [o for o in os.listdir(PATH) if 'ubyte.gz' in o] # could just use glob\n",
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thanks to: https://stackoverflow.com/a/14849322\n",
    "trn_x_idx = [i for i,s in enumerate(fnames) if 'train-imag' in s][0]\n",
    "trn_y_idx = [i for i,s in enumerate(fnames) if 'train-lab' in s][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load entire IDX files into memory as ndarrays\n",
    "train_x_array = read_IDX(PATH/fnames[trn_x_idx])\n",
    "train_y_array = read_IDX(PATH/fnames[trn_y_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44.86083984375, 0.057220458984375)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of numpy arrays in MBs\n",
    "train_x_array.nbytes / 2**20, train_y_array.nbytes / 2**20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast AI Model Data object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inception_stats` have the same Normalization that the pytorch transform above uses for its dataloader. I don't do any data augmentation besides that normalization. I also use the same train/val indices from the pytorch dataloader – to ensure my pytorch model and fastai learner are working on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_stats(inception_stats, sz=sz)\n",
    "# `inception_stats` are: ([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "# see: https://github.com/fastai/fastai/blob/master/fastai/transforms.py#L695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using same indices as pytorch dataloader\n",
    "valid_x_array, valid_y_array = train_x_array[valid_idxs], train_y_array[valid_idxs]\n",
    "train_x_array, train_y_array = train_x_array[train_idxs], train_y_array[train_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = ImageClassifierData.from_arrays(PATH, \n",
    "    (train_x_array, train_y_array), (valid_x_array, valid_y_array),\n",
    "    bs=bs, tfms=tfms, num_workers=2, test=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to have a \"solid\" simple ConvNet to use throughout these experiments. This model will include a large field-of-view input conv layer followed by several conv layers. Each conv layer uses BatchNorm and Leaky ReLU (I don't know if this is better than ReLU, but it *sounds* like a good'ish idea to me). The model's head uses an AdaptiveConcat Pooling layer (Fast AI invention that concatenates two adaptive average and max pooling layers) leading to a Linear layer. This model doesn't use dropout (I'll add that if it looks like it needs it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    \"\"\"fast.ai, see: https://github.com/fastai/fastai/tree/master/fastai/layers.py\"\"\"\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = torch.nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = torch.nn.AdaptiveAvgPool2d(sz)\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    \"\"\"fast.ai, see: https://github.com/fastai/fastai/tree/master/fastai/layers.py\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNLayer(nn.Module):\n",
    "    \"\"\"conv layer with batchnorm\"\"\"\n",
    "    def __init__(self, ch_in, ch_out, kernel_size=3, stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        self.conv  = nn.Conv2d(ch_in, ch_out, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn    = nn.BatchNorm2d(ch_out, momentum=0.1) # mom at default 0.1\n",
    "        self.lrelu = nn.LeakyReLU(0.01, inplace=True)     # neg slope at default 0.01\n",
    "    def forward(self, x): return self.lrelu(self.bn(self.conv(x)))\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    # see ref: https://github.com/fastai/fastai/blob/master/fastai/models/darknet.py\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv0   = ConvBNLayer(1, 16, kernel_size=7, stride=1, padding=2) # large FoV Conv\n",
    "        self.conv1   = ConvBNLayer(16, 32)\n",
    "        self.conv2   = ConvBNLayer(32, 64)\n",
    "        self.conv3   = ConvBNLayer(64, 128)\n",
    "        self.neck    = nn.Sequential(*[AdaptiveConcatPool2d(1), Flatten()])\n",
    "        self.head    = nn.Sequential(*[nn.BatchNorm2d(256), \n",
    "                                      nn.Dropout(p=0.25),\n",
    "                                      nn.Linear(256, 10)])        \n",
    "    def forward(self, x):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        x = self.conv0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.neck(x)\n",
    "        x = self.head(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-204-3df4356516d4>(24)forward()\n",
      "-> x = self.conv0(x)\n",
      "(Pdb) n\n",
      "> <ipython-input-204-3df4356516d4>(25)forward()\n",
      "-> x = self.conv1(x)\n",
      "(Pdb) n\n",
      "> <ipython-input-204-3df4356516d4>(26)forward()\n",
      "-> x = self.conv2(x)\n",
      "(Pdb) n\n",
      "> <ipython-input-204-3df4356516d4>(27)forward()\n",
      "-> x = self.conv3(x)\n",
      "(Pdb) n\n",
      "> <ipython-input-204-3df4356516d4>(28)forward()\n",
      "-> x = self.neck(x)\n",
      "(Pdb) x.shape # sanity check\n",
      "torch.Size([64, 128, 16, 16])\n",
      "(Pdb) AdaptiveConcatPool2d(1)(x).shape\n",
      "torch.Size([64, 256, 1, 1])\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-965816993670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconvnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-204-3df4356516d4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-204-3df4356516d4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Miniconda3/envs/fastai/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Miniconda3/envs/fastai/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x,y = next(iter(trainloader))\n",
    "x,y = Variable(x), Variable(y)\n",
    "convnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = ConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast AI Learner\n",
    "\n",
    "I'll use two fast.ai learners: the basic convnet defined above that the pytorch model will also use, and a resnet18. I'll also use an ImageNet-pretrained resnet18 to see if that helps at all. If `.pretrained` is not called, you will need to either use `ConvnetBuilder` or define a custom head yourself. **NOTE** also that the standard pytorch ResNet model has a 7x7 ouput pooling layer by default, which may restrict your model's performance if it's not replaced (such as with ConvnetBuilder).\n",
    "\n",
    "The non-pretrained learner's will need their conv layers unfrozen to train them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, False, False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.c, model_data.is_multi, model_data.is_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ConvnetBuilder(resnet18, model_data.c, model_data.is_multi, model_data.is_reg, pretrained=False)\n",
    "\n",
    "resnet_learner = ConvLearner(model_data, resnet_model)\n",
    "custom_learner = ConvLearner.from_model_data(ConvNet(), model_data)\n",
    "pt_res_learner = ConvLearner.pretrained(resnet18, model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Aside: Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Again, the learners' conv layers are initially frozen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True in [[layer.trainable for layer in layer_group] for layer_group in resnet_learner.get_layer_groups()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By default only the 'head' classification layer is trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[False, False, False, False, False, False],\n",
       " [False, False, False, False],\n",
       " [True, True, True, True, True, True, True, True]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[layer.trainable for layer in layer_group] for layer_group in resnet_learner.get_layer_groups()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Construct the custom learner with ConvnetBuilder in order to make it's layers iterable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ConvBNLayer' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-e14f1b642468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_group\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcustom_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-e14f1b642468>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_group\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcustom_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'ConvBNLayer' object is not iterable"
     ]
    }
   ],
   "source": [
    "[[layer.trainable for layer in layer_group] for layer_group in custom_learner.get_layer_groups()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.core.BasicModel at 0x133b41c50>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_learner.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.conv_learner.ConvnetBuilder at 0x13087b4e0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_learner.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# custom_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resnet_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pt_res_learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "[`torch.nn.CrossEntropyLoss`](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/loss.py#L701)\n",
    "\n",
    "Do `nn.functional.` loss functions go in the architecture, and `nn.` loss functions become criterion? [Huh, interesting. It calls `nn.functional.`](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/loss.py#L778)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.NLLLoss() # log_softmax already in arch; nll(log_softmax) <=> CE\n",
    "optimizer = torch.optim.SGD(convnet.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fast.ai Learners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.nll_loss(input, target, weight=None, size_average=True, ignore_index=-100, reduce=True)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_learner.crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.nll_loss(input, target, weight=None, size_average=True, ignore_index=-100, reduce=True)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_learner.crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.nll_loss(input, target, weight=None, size_average=True, ignore_index=-100, reduce=True)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_res_learner.crit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as I know, training in base PyTorch is tedious, so I'll do a sanity-check of it first, then do all my training with Fast AI. See ref: §4: Training or §9.1: Train ConvNet & ConvNetMod in [this notebook](https://github.com/WNoxchi/Kaukasos/blob/master/PyTorch/practice-mnist.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more improvements to doing train / valid phases – including learning rate scheduling and automatically saving best weights (see: [pytorch tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html?highlight=dataloaders#load-data)) – but that's what fast.ai's for. I'll practice those in the future. Also since the FastAI library is pending an update to PyTorch 0.4, `torch.set_grad_enabled` can't be used for inference mode. Instead I follow the advice on this [pytorch forum thread](https://discuss.pytorch.org/t/resolved-validation-loss/3501). For now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model=None, crit=None, trainloader=None, valloader=None, num_epochs=1, verbose=True):\n",
    "    # if verbose:\n",
    "    #     displays = 5\n",
    "    #     display_step = max(len(dataloader) // displays, 1)\n",
    "    t0 = time.time()\n",
    "    \n",
    "    dataloaders = {'train':trainloader}\n",
    "    if valloader: dataloaders['valid'] = valloader\n",
    "    \n",
    "    # epoch w/ train & val phases\n",
    "    for epoch in range(num_epochs): \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}\\n{\"-\"*10}')\n",
    "        \n",
    "        for phase in dataloaders:\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "            \n",
    "            for i,datum in enumerate(dataloaders[phase]):\n",
    "                inputs, labels = datum\n",
    "                inputs, labels = torch.autograd.Variable(inputs), torch.autograd.Variable(labels)\n",
    "\n",
    "                # zero param gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # (forward) track history if train\n",
    "                # with torch.set_grad_enabled(phase=='train'): # pytorch >= 0.4\n",
    "                if phase == 'valid':     # pytorch 3.1 #\n",
    "                    inputs.volatile=True               #\n",
    "                    labels.volatile=True               #\n",
    "                outputs = model(inputs)                #\n",
    "                loss    = crit(outputs, labels)        #\n",
    "                _, preds= torch.max(outputs, 1) # for accuracy metric\n",
    "                                                       #\n",
    "                # backward & optimize if train         #\n",
    "                if phase == 'train':                   #\n",
    "                    loss.backward()                    #\n",
    "                    optimizer.step()                   # indent for pytorch >= 0.4\n",
    "\n",
    "                # stats\n",
    "                running_loss += loss.data[0]\n",
    "                running_correct += torch.sum(preds == V(labels.data)) # wrap in V; pytorch 3.1\n",
    "                \n",
    "#                 print(i)\n",
    "#                 if i == 1: break\n",
    "                    \n",
    "            epoch_loss = running_loss / len(dataloaders[phase])\n",
    "#             if phase == 'valid': pdb.set_trace()\n",
    "            epoch_acc  = float(running_correct.double() / len(dataloaders[phase])) # ? pytorch 3.1 reqs float conversion?\n",
    "#             pdb.set_trace()\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                \n",
    "    time_elapsed = time.time() - t0\n",
    "    print(f'Training Time {num_epochs} Epochs: {time_elapsed:.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual PyTorch train / val training phases. See: [pytorch tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html?highlight=validation#training-the-model)\n",
    "\n",
    "*(forward) track history only if in train:*\n",
    "```\n",
    "with torch.set_grad_enabled(False):\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    loss = criterion(outputs, labels)\n",
    "```\n",
    "*backward + optimize only if in training phase*\n",
    "```\n",
    "    if phase == 'train':\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: I think I'm doing something wrong with the validation phase. [Saving](https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/7?u=wnixalo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 2.2973 Acc: 0.2823\n",
      "valid Loss: 2.3003 Acc: 0.3050\n",
      "Training Time 1 Epochs: 260.858s\n"
     ]
    }
   ],
   "source": [
    "train(model=convnet, crit=criterion, trainloader=trainloader, valloader=validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WayNoxchi/Miniconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type ConvNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/WayNoxchi/Miniconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type ConvBNLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(convnet.state_dict, 'convnet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with Fast AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (FastAI)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
