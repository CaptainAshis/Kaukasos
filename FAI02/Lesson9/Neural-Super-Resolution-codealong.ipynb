{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Super Resolution (codealong)\n",
    "\n",
    "---\n",
    "FADL2 Cutting Edge Deep Learning - Lesson 9: Generative Models\n",
    "\n",
    "Wayne Nixalo - 10 Aug 2017\n",
    "\n",
    "Lesson 9 NB: [neural-sr.ipynb](https://github.com/fastai/courses/blob/master/deeplearning2/neural-sr.ipynb)\n",
    "\n",
    "---\n",
    "This is more/less making sure I got the basic understanding of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains implementation of a super-resolution network trained on ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import sys, os; sys.path.insert(1, os.path.join('../utils'))\n",
    "from utils2 import *\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.misc import imsave\n",
    "from keras import metrics\n",
    "from vgg16_avg import VGG16_Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bcolz_array_iterator import BcolzArrayIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = '/data/sr-imgs/'\n",
    "# dpath = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code is identical to the implementation shown in the neural-style notebook, with the exception of the BcolzArrayIterator training implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rn_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n",
    "preproc = lambda x: (x - rn_mean)[:,:,:,::-1]\n",
    "deproc  = lambda x,s: np.clip(x.reshape(s)[:,:,:,::-1] + rn_mean, 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't load ImageNet into memory, so we open the files and then pass them to the generator BcolzArrayIterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dpath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6b3701153098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marr_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'trn_resized_72_r.bc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0marr_hr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'results/trn_resized_288_r.bc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dpath' is not defined"
     ]
    }
   ],
   "source": [
    "arr_lr = bcolz.open(dpath + 'trn_resized_72_r.bc')\n",
    "arr_hr = bcolz.open(path  + 'results/trn_resized_288_r.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pars = {'verbose': 0, 'callbacks': [TQDMNotebookCallback(leave_inner=True)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters, size, stride=(2,2), mode='same', act=True):\n",
    "    x = Convolution2D(filters, size, size, subsample=stride, border_mode=mode)(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    return Activation('relu')(x) if act else x\n",
    "\n",
    "def res_block(ip, nf=64):\n",
    "    x = conv_block(ip, nf, 3, (1,1))\n",
    "    x = conv_block(x, nf, 3, (1,1), act=False)\n",
    "    return merge([x, ip], mode='sum')\n",
    "\n",
    "def up_block(x, filters, size):\n",
    "    x = keras.layers.UpSampling2D()(x)\n",
    "    x = Convolution2D(filters, size, size, border_mode='same')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def get_model(arr):\n",
    "    inp=Input(arr.shape[1:])\n",
    "    x=conv_block(inp, 64, 9, (1,1))\n",
    "    for i in range(4): x=res_block(x)\n",
    "    x=up_block(x, 64, 3)\n",
    "    x=up_block(x, 64, 3)\n",
    "    x=Convolution2D(3, 9, 9, activation='tanh', border_mode='same')(x)\n",
    "    outp=Lambda(lambda x: (x+1)*127.5)(x)\n",
    "    return inp,outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp, outp - get_model(arr_lr)\n",
    "shp = arr_hr.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_inp=Input(shp)\n",
    "vgg=VGG16(include_top=False, input_tensor=Lambda(preproc)(vgg_inp))\n",
    "for λ in vgg.layers: λ.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outp(m, λn): return m.get_layer(f'block{λn}_conv2').output\n",
    "\n",
    "vgg_content = Model(vgg_inp, [get_outp(vgg, o) for o in [1,2,3]])\n",
    "vgg1 = vgg_content(vgg_inp)\n",
    "vgg2 = vgg_content(outp)\n",
    "\n",
    "def mean_sqr_b(diff):\n",
    "    dims = list(range(1, K.ndim(diff)))\n",
    "    return K.expand_dims(K.sqrt(K.mean(diff**2, dims)), 0)\n",
    "\n",
    "w = [0.1, 0.8, 0.1]\n",
    "\n",
    "def content_fn(x):\n",
    "    res = 0; n = len(w)\n",
    "    for i in range(n): res += mean_sqr_b(x[i] - x[i+n]) * w[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_sr = Model([inp, vgg_inp], Lambda(content_fn)(vgg1 + vgg2))\n",
    "m_sr.compile('adam', 'mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training implementation has been altered to accomodate the BcolzArrayIterator.\n",
    "\n",
    "We're unable to use model.fit_generator() because that function call expects the generator to return a tuple of inputs and targets.\n",
    "\n",
    "Our generator howeve,r yields two inputs. We can work around this by separately pulling out our inputs from the generator and then using `model.train_on_batch()` with our inputs from the generator and our dummy targets. `model.train_on_batch()` simply does one gradient update on the batch of data.\n",
    "\n",
    "This technique of creating your own training loop is useful when you are working with various iterators or complicated inputs that don't conform to Keras' standard fitting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(bs, niter=10):\n",
    "    targ = np.zeros((bs, 1))\n",
    "    bc = BcolzArrayIterator(arr_hr, arr_lr, batch_size=bs)\n",
    "    for i in range(niter):\n",
    "        hr, λr = next(bc)\n",
    "        m_sr.train_on_batch([λr[:bs], hr[:bs]], targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "its = len(arr_hr)//16; its"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time train(16, 18000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(m_sr.optimizer.lr, 1e-4)\n",
    "train(16, 18000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model = Model(inp, outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = top_model.predict(arr_lr[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_file = '----/ILSVRC2012_val_00005642.JPEG''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = Image.open(new_file).resize((288, 288))\n",
    "img_dat = np.expand_dims(np.array(img),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some results after training on ~ half of ImageNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(img_dat[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = model_hr.predict(img_dat)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(p[0].astype('uint8'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx=4\n",
    "plt.imshow(arr_hr[idx].astype('uint8'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(arr_lr[idx].astype('uint8'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(p[idx].astype('uint8'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the CNN is fully convolutional, we can use it on images of arbitrary size. Let's try it w/ the high-res as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp, outp = get_model(arr_hr)\n",
    "model_hr = Model(inp, outp)\n",
    "copy_weights(top_model.layers, model_hr.layers)\n",
    "\n",
    "p = model_hr.predict(arr_hr[idx:idx+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of this prediction is very impressive given that this model was trained on the low-res images.\n",
    "\n",
    "One take-away here is that this suggests that upsampling such a model is somewhat independent of resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(p[0].astype('uint8'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(arr_hr[idx].astype('uint8'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model.save_weights(dpath + 'sr_final.h5')\n",
    "# top_model.load_weights(dpath + 'sr_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (FAI)",
   "language": "python",
   "name": "fai3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
