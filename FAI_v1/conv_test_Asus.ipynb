{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9 June 2017**\n",
    "\n",
    "Wayne Nixalo\n",
    "\n",
    "This notebook started out trying to generate convolutional test features using ```Sequential.predict_generator```, by using ```bcolz``` to save the generated features to disk, in batches as they were created. This was successful after a few days of work. (roughly: 6 - 9 June).\n",
    "\n",
    "This notebook's continued on to build a full set of submittable predictions. Once that's solved, I can build a strong model, unconstrained by system memory limits. Video-memory is another matter, at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wnixalo/miniconda3/envs/FAI/lib/python2.7/site-packages/theano/gpuarray/dnn.py:135: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to version 5.1.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 870M (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, os.path.join('utils'))\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "path = 'data/statefarm/'\n",
    "import utils; reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "vgg = Vgg16()\n",
    "model = vgg.model\n",
    "last_conv_idx = [i for i, l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx + 1]\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "test_batches = get_batches(path + 'test', batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual iteration through test image to generate convolutional test features. Saves each batch to disk insetad of loading in memory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conv_test_feat = conv_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think ```conv_feat``` below should be ```conv_test_feat```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'data/statefarm/results/conv_feat_test.dat': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "fname = path + 'results/conv_test_feat.dat'\n",
    "%rm -r $fname\n",
    "for i in xrange(test_batches.n // batch_size + 1):\n",
    "    conv_test_feat = conv_model.predict_on_batch(test_batches.next()[0])\n",
    "    if not i:\n",
    "        c = bcolz.carray(conv_feat, rootdir= path + '/results/conv_test_feat.dat', mode='a')\n",
    "    else:\n",
    "        c.append(conv_feat)\n",
    "c.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Why does it look like I can have the entire conv_test_feat array open at once, when opened w/ bcolz; but when it's explicitly loaded as a Numpy array via ```bcolz.open(fname)[:]```, all of a sudden the RAM takes a severe memory hit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79712"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apparently you can just open a (massive) bcolz carray this way \n",
    "# without crashing memory... okay I'm learning things\n",
    "# carr = bcolz.open(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forgot to add the '+1' so missed the last 14 images. Doing that here:\n",
    "# NOTE: below code only adds on the missed batch\n",
    "# iterate generator until final missed batch, then work:\n",
    "fname = path + 'results/conv_test_feat.dat'\n",
    "test_batches.reset()\n",
    "iters = test_batches.n // batch_size\n",
    "for i in xrange(iters): test_batches.next()\n",
    "conv_test_feat = conv_model.predict_on_batch(test_batches.next()[0])\n",
    "# c = bcolz.carray(conv_test_feat, rootdir=fname, mode='a')\n",
    "c = bcolz.open(fname)\n",
    "c.append(conv_test_feat)\n",
    "c.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As expected (& which motivated this) the full set of convolutional test features does not fit at once in memory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = path + 'results/conv_test_feat.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79726"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = bcolz.open(fname)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading train/valid features; defining & fitting NN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conv_train_feat_batches = get_batches(path + '/results/conv_feat.dat')\n",
    "# conv_valid_feat_batches = get_batches(path + '/results/conv_val_feat.dat')\n",
    "conv_trn_feat = load_array(path + '/results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path + '/results/conv_val_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19463 images belonging to 10 classes.\n",
      "Found 2961 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.8\n",
    "bn_model = Sequential([\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "bn_model.compile(Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequential.fit_generator(self, generator, samples_per_epoch, nb_epoch, verbose=1, callbacks=None, validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10, nb_worker=1, pickle_safe=False, initial_epoch=0, **kwargs)\n",
    "# bn_model.fit_generator((conv_train_feat_batches, trn_labels), conv_train_feat_batches.nb_sample, nb_epoch=1,\n",
    "#                        validation_data=(conv_valid_feat_batches, val_labels), nb_val_samples=conv_valid_feat_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/1\n",
      "19463/19463 [==============================] - 8s - loss: 1.4585 - acc: 0.5945 - val_loss: 0.7479 - val_acc: 0.7207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb53ffbc210>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=1,\n",
    "             validation_data = (conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/4\n",
      "19463/19463 [==============================] - 8s - loss: 0.2751 - acc: 0.9171 - val_loss: 0.5394 - val_acc: 0.8173\n",
      "Epoch 2/4\n",
      "19463/19463 [==============================] - 8s - loss: 0.1748 - acc: 0.9462 - val_loss: 0.6580 - val_acc: 0.7693\n",
      "Epoch 3/4\n",
      "19463/19463 [==============================] - 8s - loss: 0.1337 - acc: 0.9578 - val_loss: 0.7747 - val_acc: 0.7305\n",
      "Epoch 4/4\n",
      "19463/19463 [==============================] - 8s - loss: 0.1088 - acc: 0.9670 - val_loss: 0.8638 - val_acc: 0.7518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb53fbae410>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.optimizer.lr=1e-2\n",
    "bn_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=4,\n",
    "             validation_data = (conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bn_model.save_weights(path + 'models/da_conv8.h5')\n",
    "bn_model.load_weights(path + 'models/da_conv8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81920\n",
      "Ya done fucked up, son.\n"
     ]
    }
   ],
   "source": [
    "# conv_test_feat_batches = bcolz.iterblocks(path + fname)\n",
    "fname = path + 'results/conv_test_feat.dat'\n",
    "idx, inc = 0, 4096\n",
    "preds = []\n",
    "while idx < test_batches.n - inc:\n",
    "    conv_test_feat = bcolz.open(fname)[idx:idx+inc]\n",
    "    idx += inc\n",
    "    if len(preds):\n",
    "        next_preds = bn_model.predict(conv_test_feat, batch_size=batch_size, verbose=0)\n",
    "        preds = np.concatenate([preds, next_preds])\n",
    "    else:\n",
    "        preds = bn_model.predict(conv_test_feat, batch_size=batch_size, verbose=0)\n",
    "conv_test_feat = bcolz.open(fname)[idx:]\n",
    "next_preds = bn_model.predict(conv_test_feat, batch_size=batch_size, verbose=0)\n",
    "preds = np.concatenate([preds, next_preds])\n",
    "print(len(preds))\n",
    "if len(preds) != len(bcolz.open(fname)):\n",
    "    print(\"Ya done fucked up, son.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made a mistake on the last loop above. The penultimate batch -- the last full 4096-image batch -- was added onto the end of the predictions array twice. The final 2194 image predictions were never run.\n",
    "\n",
    "Easy enough to fix: modify the above code to work perfectly. Then *either*:\n",
    "* create entirely new predictions from scratch (~ 1 hour)\n",
    "* remove the last increment (4096) of predictions from the array, and add the last batch.\n",
    "\n",
    "Gonna take option 2.\n",
    "\n",
    "EDIT:\n",
    "\n",
    "actually, option 1. ```preds``` was stored in memory, which was erased when I closed this machine for the night. So this time I'll just build the predictions array properly.\n",
    "\n",
    "**Below is testing/debugging output from the night before**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2194\n",
      "1902\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(81920 - 79726)\n",
    "print(79726 % 4096)\n",
    "print(81920 % 4096) # <-- that's yeh problem right there, kid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = preds[len(preds) - 4096]\n",
    "print(preds[-1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.2483e-07,   2.4578e-06,   2.9354e-05,   6.7996e-05,   8.1581e-07,   2.9132e-06,\n",
       "          9.9981e-01,   2.7024e-07,   8.0846e-05,   3.0252e-06],\n",
       "       [  4.0233e-04,   3.4477e-05,   7.3304e-07,   3.4403e-01,   6.5541e-01,   9.2372e-06,\n",
       "          7.4395e-05,   8.1555e-06,   1.8162e-05,   8.2546e-06],\n",
       "       [  3.7808e-06,   1.2269e-06,   4.5053e-07,   3.5392e-06,   1.5726e-05,   3.7257e-06,\n",
       "          1.5923e-05,   7.0004e-06,   9.9993e-01,   2.0967e-05],\n",
       "       [  2.1178e-05,   6.0503e-06,   1.8488e-06,   7.9847e-06,   7.7963e-06,   9.9988e-01,\n",
       "          3.8778e-05,   4.0426e-06,   1.3915e-05,   1.8222e-05],\n",
       "       [  4.2161e-01,   1.3603e-04,   9.1913e-02,   5.2514e-04,   4.0447e-02,   2.0817e-01,\n",
       "          1.7152e-02,   3.7824e-03,   2.7693e-02,   1.8857e-01],\n",
       "       [  6.9312e-04,   5.2366e-02,   1.6738e-05,   5.5922e-06,   3.7776e-05,   1.1497e-04,\n",
       "          1.4271e-05,   9.1994e-05,   6.5573e-05,   9.4659e-01],\n",
       "       [  9.8337e-10,   4.1691e-08,   2.3664e-07,   4.8789e-09,   2.7257e-08,   2.3041e-08,\n",
       "          2.1754e-07,   1.0000e+00,   5.1427e-07,   2.3709e-09],\n",
       "       [  1.1594e-06,   5.4730e-09,   2.5601e-09,   8.1659e-09,   5.9669e-06,   9.9999e-01,\n",
       "          5.0917e-07,   1.1032e-06,   3.9713e-07,   2.8886e-09],\n",
       "       [  9.6761e-05,   9.8503e-01,   2.0876e-04,   1.8814e-05,   8.8029e-05,   1.1453e-04,\n",
       "          1.1641e-02,   4.8791e-05,   2.6841e-03,   7.0924e-05],\n",
       "       [  6.7607e-06,   1.3271e-07,   9.9734e-01,   9.7243e-06,   5.7442e-04,   1.3320e-05,\n",
       "          5.3985e-07,   1.3169e-03,   1.1960e-04,   6.1661e-04]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.4223e-07,   4.0707e-05,   5.6510e-05,   1.0678e-05,   1.6999e-04,   3.3456e-03,\n",
       "         2.3427e-05,   9.9596e-01,   9.5046e-05,   2.9750e-04], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ??image.ImageDataGenerator.flow_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ??Sequential.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Redoing predictions here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79726\n"
     ]
    }
   ],
   "source": [
    "fname = path + 'results/conv_test_feat.dat'\n",
    "idx, inc = 4096, 4096\n",
    "preds = []\n",
    "\n",
    "conv_test_feat = bcolz.open(fname)[:idx]\n",
    "preds = bn_model.predict(conv_test_feat, batch_size=batch_size, verbose=0)\n",
    "while idx < test_batches.n - inc:\n",
    "    conv_test_feat = bcolz.open(fname)[idx:idx+inc]\n",
    "    idx += inc\n",
    "    next_preds = bn_model.predict(conv_test_feat, batch_size=batch_size, verbose=0)\n",
    "    preds = np.concatenate([preds, next_preds])\n",
    "conv_test_feat = bcolz.open(fname)[idx:]\n",
    "next_preds = bn_model.predict(conv_test_feat, batch_size=batch_size, verbose=0)\n",
    "preds = np.concatenate([preds, next_preds])\n",
    "\n",
    "print(len(preds))\n",
    "if len(preds) != len(bcolz.open(fname)):\n",
    "    print(\"Ya done fucked up, son.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh I forgot, predictions through a FC NN are *fast*. CNNs are where it takes a *long* time.\n",
    "\n",
    "This is just quick testing that it works. Full/polished will be in the reworked statefarm-codealong (or just statefarm) JNB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds, 0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = path + 'results/subm01.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19463 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "trn_batches = get_batches(path + 'train', batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure training batches defined before this:\n",
    "classes = sorted(trn_batches.class_indices, key=trn_batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_93169.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_81727.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_53095.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_13927.jpg</td>\n",
       "      <td>0.052475</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.081378</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.857765</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_36496.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img        c0        c1        c2        c3        c4        c5  \\\n",
       "0  img_93169.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.007778   \n",
       "1  img_81727.jpg  0.007778  0.007778  0.007778  0.930000  0.007778  0.007778   \n",
       "2  img_53095.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.007778   \n",
       "3  img_13927.jpg  0.052475  0.007778  0.007778  0.007778  0.081378  0.007778   \n",
       "4  img_36496.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.007778   \n",
       "\n",
       "         c6        c7        c8        c9  \n",
       "0  0.007778  0.930000  0.007778  0.007778  \n",
       "1  0.007778  0.007778  0.007778  0.007778  \n",
       "2  0.930000  0.007778  0.007778  0.007778  \n",
       "3  0.007778  0.007778  0.857765  0.007778  \n",
       "4  0.007778  0.930000  0.007778  0.007778  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'img', [f[8:] for f in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/statefarm/results/subm01.gz' target='_blank'>data/statefarm/results/subm01.gz</a><br>"
      ],
      "text/plain": [
       "/home/wnixalo/Kaukasos/FAI/data/statefarm/results/subm01.gz"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This 'just good enough to pass' code/model got a 0.70947 on the Kaggle competition. My previous best was 1.50925 at place 658/1440; top ~45.7%. This gets place 415/1440. Top ~28.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
