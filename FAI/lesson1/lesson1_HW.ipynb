{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAI1 - Practical Deep Learning I\n",
    "Homework Jupyter Notebook for Lesson 1: Image Classification\n",
    "\n",
    "See the full course at: http://course.fast.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "Keras requires a directory structure based on the classes you are looking at. Our directory structure will be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dogscats/\n",
    "#     train/\n",
    "#         dogs/\n",
    "#         cats/\n",
    "#     valid/\n",
    "#         dogs/\n",
    "#         cats/\n",
    "#     test/\n",
    "#         dogs/\n",
    "#         cats/\n",
    "#     sample/\n",
    "#         <same as for dogscats/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making sure python knows where to look for my utilities folder (it's in this notebook's parent folder).\n",
    "# I know the naming can be confusing, but it's to not get in the way of the imports below\n",
    "from os import path as ospath, getcwd; from sys import path as syspath\n",
    "current_dir = getcwd()\n",
    "syspath.insert(1, ospath.join(current_dir, '../utils'))\n",
    "syspath.insert(1, ospath.join(current_dir, '..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup matplotlib to plot inside the notebook, import NumPy, SciPy, VGG, and the appropriate Keras libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this ensures matplotlib plots within this window\n",
    "%matplotlib inline\n",
    "# path to my sample data directory. Contains 180 imgs in ../train/ and 20 \n",
    "# imgs in ../valid/ The full dataset contains 25,000 imgs.\n",
    "path = 'data/dogscats/sample/'\n",
    "# The libraries to be imported (taken from https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson1.ipynb)\n",
    "from __future__ import division, print_function\n",
    "import os, json\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import utils; reload(utils)\n",
    "from utils import plots\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vgg16 Image Recognition Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a small test-run of Vgg16 to show what the data & labels look like. Afterwards we'll finetune & fit the model to our dataset (so that Vgg16 is looking for cats vs dogs instead of its standard 1,000 categories), run it on our full test set, and create a submissions csv file to upload to Kaggle and get scored.\n",
    "\n",
    "First create a Vgg16 object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some batches from the sample training folder. vgg.get_batches(..) is an iterator that returns a batch of images and their labels, indefinitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = vgg.get_batches(path+'train',batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs, labels = next(batches)\n",
    "plots(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of the categories Vgg16 usually works with, here're the first 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.classes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vgg16 finetuned for Dogs vs Cats:\n",
    "What we do now is finetune and fit our model to our specific dataset. Finetuning further trains a pre-trained Machine-Learning model (Vgg16). A training set is trained on, and a validation set is tested against. In finetuning, we're only changing a small subset of our model's parameters since our pre-trained model is already very close to our final desired model. This is done by calling fit() after calling finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batches = vg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling fineunte() modifies the model so that it'll be trained based on the data in the batches provided: dog vs cat. The model's parameters are then fitted using the training data, and accuracy is reported using teh validation set. An epoch is 1 full pass through the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.finetune(batches)\n",
    "vgg.fit(batches, val_batches, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More training\n",
    "To try and get into the top 50% of the Cats v Dogs Redux competition, I'm going to train the model for a few more epochs and see how that works out. I'm also going to tune the learning rate to η = 0.01 and see how that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 3\n",
    "vgg.model.optimizer.lr = 0.01\n",
    "for epoch in xrange(nb_epoch):\n",
    "    print \"Starting Epoch %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=nb_epoch)\n",
    "print \"Completed %d fit operations\" % nb_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is ready to classify dogs vs cats. In order to complete this assignment, we'll have to create a csv (comma-separated-values) file of IDs and labels of the full 25,000 set of images and upload it to Kaggle for scoring.\n",
    "\n",
    "First modify the path to the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/dogscats/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vgg.test(..) will return the entire set of batches & predictions (labels). We'll extract the ID-number from batches.filenames, and the label from the second column of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches, predictions = vgg.test(path+'test',batch_size=batch_size)\n",
    "filenames = batches.filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for getting the IDs below is: make an array of the index of the period plus one, to fourth-from-end character, of each item f in filenames. The file extensions are all \".jpg\" which is 4 characters long, and the ID number of each file comes after a period as such: \"dog.0010.jpg\" or \"cat.1001.jpg\" & etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.array([int(f[f.find('.')+1:-4]) for f in filenames])\n",
    "dog_predictions = predictions[:,1]\n",
    "submission = np.stack([ids, dog_predictions], axis=1)\n",
    "submission_file_name = 'submission_HW1_.csv'\n",
    "np.savetxt(submission_file_name, submission, fmt='%d,%.5f',header='id,label',comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it kurzgesagt.\n",
    "Find the original Jupyter Notebook here: https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson1.ipynb\n",
    "\n",
    "And a great walkthrough here: https://github.com/fastai/courses/blob/master/deeplearning1/nbs/dogs_cats_redux.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WH Nixalo - 1 Seli 2017 12:47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:\n",
    "1 May 2017 -- single finetune & fitting epoch, default η: \n",
    "\n",
    "* E =  0.16309, Rank: 734/1314\n",
    "\n",
    "6 May 2017 -- 4 epochs, η = 0.01 for last 3: \n",
    "\n",
    "* E = TBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
