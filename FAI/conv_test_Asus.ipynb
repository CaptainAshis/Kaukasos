{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wnixalo/miniconda3/envs/FAI/lib/python2.7/site-packages/theano/gpuarray/dnn.py:135: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to version 5.1.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 870M (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, os.path.join('utils'))\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "path = 'data/statefarm/'\n",
    "import utils; reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "vgg = Vgg16()\n",
    "model = vgg.model\n",
    "last_conv_idx = [i for i, l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx + 1]\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "test_batches = get_batches(path + 'test', batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual iteration through test image to generate convolutional test features. Saves each batch to disk insetad of loading in memory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conv_test_feat = conv_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'data/statefarm/results/conv_feat_test.dat': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "fname = path + 'results/conv_test_feat.dat'\n",
    "%rm -r $fname\n",
    "for i in xrange(test_batches.n // batch_size + 1):\n",
    "    conv_test_feat = conv_model.predict_on_batch(test_batches.next()[0])\n",
    "    if not i:\n",
    "        c = bcolz.carray(conv_feat, rootdir= path + '/results/conv_test_feat.dat', mode='a')\n",
    "    else:\n",
    "        c.append(conv_feat)\n",
    "c.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Why does it look like I can have the entire conv_test_feat array open at once, when opened w/ bcolz; but when it's explicitly loaded as a Numpy array via ```bcolz.open(fname)[:]```, all of a sudden the RAM takes a severe memory hit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79712"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apparently you can just open a (massive) bcolz carray this way \n",
    "# without crashing memory... okay I'm learning things\n",
    "# carr = bcolz.open(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forgot to add the '+1' so missed the last 14 images. Doing that here:\n",
    "# iterate generator until final missed batch, then work:\n",
    "fname = path + 'results/conv_test_feat.dat'\n",
    "test_batches.reset()\n",
    "iters = test_batches.n // batch_size\n",
    "for i in xrange(iters): test_batches.next()\n",
    "conv_test_feat = conv_model.predict_on_batch(test_batches.next()[0])\n",
    "# c = bcolz.carray(conv_test_feat, rootdir=fname, mode='a')\n",
    "c = bcolz.open(fname)\n",
    "c.append(conv_test_feat)\n",
    "c.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As expected (& which motivated this) the full set of convolutional test features does not fit at once in memory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79726"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = bcolz.open(fname)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading train/valid features; defining & fitting NN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_train_feat_batches = get_batches(path + '/results/conv_feat.dat')\n",
    "# conv_valid_feat_batches = get_batches(path + '/results/conv_val_feat.dat')\n",
    "conv_trn_feat = load_array(path + '/results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path + '/results/conv_val_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19463 images belonging to 10 classes.\n",
      "Found 2961 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.8\n",
    "bn_model = Sequential([\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "bn_model.compile(Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequential.fit_generator(self, generator, samples_per_epoch, nb_epoch, verbose=1, callbacks=None, validation_data=None, nb_val_samples=None, class_weight=None, max_q_size=10, nb_worker=1, pickle_safe=False, initial_epoch=0, **kwargs)\n",
    "# bn_model.fit_generator((conv_train_feat_batches, trn_labels), conv_train_feat_batches.nb_sample, nb_epoch=1,\n",
    "#                        validation_data=(conv_valid_feat_batches, val_labels), nb_val_samples=conv_valid_feat_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/1\n",
      "19463/19463 [==============================] - 8s - loss: 1.4585 - acc: 0.5945 - val_loss: 0.7479 - val_acc: 0.7207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb53ffbc210>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=1,\n",
    "             validation_data = (conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/4\n",
      "19463/19463 [==============================] - 8s - loss: 0.2751 - acc: 0.9171 - val_loss: 0.5394 - val_acc: 0.8173\n",
      "Epoch 2/4\n",
      "19463/19463 [==============================] - 8s - loss: 0.1748 - acc: 0.9462 - val_loss: 0.6580 - val_acc: 0.7693\n",
      "Epoch 3/4\n",
      "19463/19463 [==============================] - 8s - loss: 0.1337 - acc: 0.9578 - val_loss: 0.7747 - val_acc: 0.7305\n",
      "Epoch 4/4\n",
      "19463/19463 [==============================] - 8s - loss: 0.1088 - acc: 0.9670 - val_loss: 0.8638 - val_acc: 0.7518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb53fbae410>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.optimizer.lr=1e-2\n",
    "bn_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=4,\n",
    "             validation_data = (conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path + 'models/da_conv8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81920\n",
      "Ya done fucked up, son.\n"
     ]
    }
   ],
   "source": [
    "# conv_test_feat_batches = bcolz.iterblocks(path + fname)\n",
    "fname = path + 'results/conv_test_feat.dat'\n",
    "idx, inc = 0, 4096\n",
    "preds = []\n",
    "while idx < test_batches.n - inc:\n",
    "    conv_test_feat = bcolz.open(fname)[idx:idx+inc]\n",
    "    idx += inc\n",
    "    if len(preds):\n",
    "        next_preds = bn_model.predict(conv_test_feat, batch_size=batch_size, verbose=0)\n",
    "        preds = np.concatenate([preds, next_preds])\n",
    "    else:\n",
    "        preds = bn_model.predict(conv_test_feat, batch_size=batch_size, verbose=0)\n",
    "conv_test_feat = bcolz.open(fname)[idx:]\n",
    "next_preds = bn_model.predict(conv_test_feat, batch_size=batch_size, verbose=0)\n",
    "preds = np.concatenate([preds, next_preds])\n",
    "print(len(preds))\n",
    "if len(preds) != len(bcolz.open(fname)):\n",
    "    print(\"Ya done fucked up, son.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2194\n",
      "1902\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(81920 - 79726)\n",
    "print(79726 % 4096)\n",
    "print(81920 % 4096) # <-- that's yeh problem right there, kid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = preds[len(preds) - 4096]\n",
    "print(preds[-1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.2483e-07,   2.4578e-06,   2.9354e-05,   6.7996e-05,   8.1581e-07,   2.9132e-06,\n",
       "          9.9981e-01,   2.7024e-07,   8.0846e-05,   3.0252e-06],\n",
       "       [  4.0233e-04,   3.4477e-05,   7.3304e-07,   3.4403e-01,   6.5541e-01,   9.2372e-06,\n",
       "          7.4395e-05,   8.1555e-06,   1.8162e-05,   8.2546e-06],\n",
       "       [  3.7808e-06,   1.2269e-06,   4.5053e-07,   3.5392e-06,   1.5726e-05,   3.7257e-06,\n",
       "          1.5923e-05,   7.0004e-06,   9.9993e-01,   2.0967e-05],\n",
       "       [  2.1178e-05,   6.0503e-06,   1.8488e-06,   7.9847e-06,   7.7963e-06,   9.9988e-01,\n",
       "          3.8778e-05,   4.0426e-06,   1.3915e-05,   1.8222e-05],\n",
       "       [  4.2161e-01,   1.3603e-04,   9.1913e-02,   5.2514e-04,   4.0447e-02,   2.0817e-01,\n",
       "          1.7152e-02,   3.7824e-03,   2.7693e-02,   1.8857e-01],\n",
       "       [  6.9312e-04,   5.2366e-02,   1.6738e-05,   5.5922e-06,   3.7776e-05,   1.1497e-04,\n",
       "          1.4271e-05,   9.1994e-05,   6.5573e-05,   9.4659e-01],\n",
       "       [  9.8337e-10,   4.1691e-08,   2.3664e-07,   4.8789e-09,   2.7257e-08,   2.3041e-08,\n",
       "          2.1754e-07,   1.0000e+00,   5.1427e-07,   2.3709e-09],\n",
       "       [  1.1594e-06,   5.4730e-09,   2.5601e-09,   8.1659e-09,   5.9669e-06,   9.9999e-01,\n",
       "          5.0917e-07,   1.1032e-06,   3.9713e-07,   2.8886e-09],\n",
       "       [  9.6761e-05,   9.8503e-01,   2.0876e-04,   1.8814e-05,   8.8029e-05,   1.1453e-04,\n",
       "          1.1641e-02,   4.8791e-05,   2.6841e-03,   7.0924e-05],\n",
       "       [  6.7607e-06,   1.3271e-07,   9.9734e-01,   9.7243e-06,   5.7442e-04,   1.3320e-05,\n",
       "          5.3985e-07,   1.3169e-03,   1.1960e-04,   6.1661e-04]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.4223e-07,   4.0707e-05,   5.6510e-05,   1.0678e-05,   1.6999e-04,   3.3456e-03,\n",
       "         2.3427e-05,   9.9596e-01,   9.5046e-05,   2.9750e-04], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ??image.ImageDataGenerator.flow_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??Sequential.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7edc17f87a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/WayNoxchi/Miniconda3/envs/FAI/lib/python2.7/site-packages/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,0,0]])\n",
    "y = np.array([[1,0,1],[1,1,1],[0,0,1]])\n",
    "z = np.stack((x,y), axis=0)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
