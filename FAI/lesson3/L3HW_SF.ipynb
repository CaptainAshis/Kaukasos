{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Wayne Nixalo  -  20 May 2017\n",
    "FAI1 - Practical Deep Learning I - Week 3 HW: Kaggle StateFarm Distracted Driver Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Dense\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wnixalo/miniconda3/envs/FAI/lib/python2.7/site-packages/theano/gpuarray/dnn.py:135: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to version 5.1.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 870M (0000:01:00.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# will need this to access any libraries in superdirectories\n",
    "sys.path.insert(1, os.path.join(os.getcwd(), '../utils'))\n",
    "import utils\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Run this the First Time Only\n",
    "\n",
    "Download the Data and get it into the right directories. Fortunately SF already organized the data, so it's just a matter of assigning path variables. NOTE: kaggle-cli needs to be set up beforhand. Also path vars must be assigned each time this notebook is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOME_DIR = os.getcwd()\n",
    "DATA_PATH = HOME_DIR + '/data'\n",
    "TRAIN_PATH = DATA_PATH + '/train'\n",
    "VAL_PATH = DATA_PATH + '/valid'\n",
    "TEST_PATH = DATA_PATH + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the validation directories\n",
    "os.mkdir(VAL_PATH)\n",
    "for i in xrange(10):\n",
    "    os.mkdir(VAL_PATH + '/c' + str(i))\n",
    "\n",
    "# # another way to do this:\n",
    "# %mkdir $VAL_PATH\n",
    "# for i in xrange(10):\n",
    "#     %mkdir $VAL_PATH/c\"$i\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run this if you don't have an Accurate Validation Set\n",
    "\n",
    "Grab a random permutation from the training data for validation. Do this until validation accuracy matches test accuracy. Also see: http://stackoverflow.com/questions/2632205/how-to-count-the-number-of-files-in-a-directory-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train/c0\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train/c1\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train/c2\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train/c3\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train/c4\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train/c5\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train/c6\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train/c7\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train/c8\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train/c9\n",
      "/home/wnixalo/Kaukasos/FAI/lesson3/data/train\n"
     ]
    }
   ],
   "source": [
    "%cd $TRAIN_PATH\n",
    "\n",
    "VAL_PORTION = 0.2\n",
    "for i in xrange(10):\n",
    "    %cd c\"$i\"\n",
    "    g = glob('*.jpg')\n",
    "    number = len(g)\n",
    "    shuff = np.random.permutation(g)\n",
    "    for n in xrange(int(number * VAL_PORTION)):\n",
    "        os.rename(shuff[n], VAL_PATH + '/c' + str(i) + '/' + shuff[n])\n",
    "    % cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some more setup\n",
    "data_path    = DATA_DIR  + '/'\n",
    "train_path   = TRAIN_DIR + '/'\n",
    "valid_path   = VAL_DIR   + '/'\n",
    "test_path    = TEST_DIR  + '/'\n",
    "results_path = DATA_DIR  + '/results/'\n",
    "\n",
    "batch_size = 64\n",
    "# no_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch generator to feed data into the model\n",
    "gen = image.ImageDataGenerator()\n",
    "trn_batches = gen.flow_from_directory(train_path, target_size=(640,480),\n",
    "                class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "val_batches = gen.flow_from_directory(valid_path, target_size=(640, 480),\n",
    "                class_mode='categorical', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the VGG model, download its weights, and finetune it to the data\n",
    "VGGModel = Vgg16()\n",
    "VGGModel.pop()\n",
    "for layer in VGGModel.layers: layer.trainable = False\n",
    "VGGModel.add(Dense(10, activation='softmax'))\n",
    "VGGModel.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the model until it overfits\n",
    "VGGModel.optimizer.lr = 0.001\n",
    "VGGModel.fit_generator(trn_batches, trn_batches.n, nb_epoch=1, verbose=1,\n",
    "                       validation_data=val_batches, nb_val_samples=val_batches.n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
