{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Wayne Nixalo  -  20 May 2017\n",
    "FAI1 - Practical Deep Learning I - Week 3 HW: Kaggle StateFarm Distracted Driver Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/wnixalo/miniconda3/envs/FAI/lib/python2.7/site-packages/theano/gpuarray/dnn.py:135: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to version 5.1.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 870M (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Dense\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# will need this to access any libraries in superdirectories\n",
    "sys.path.insert(1, os.path.join(os.getcwd(), '../utils'))\n",
    "import utils\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Run this the First Time Only\n",
    "\n",
    "Download the Data and get it into the right directories. Fortunately SF already organized the data, so it's just a matter of assigning path variables. NOTE: kaggle-cli needs to be set up beforhand. Also path vars must be assigned each time this notebook is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOME_DIR = os.getcwd()\n",
    "DATA_DIR = HOME_DIR + '/data'\n",
    "TRAIN_DIR = DATA_DIR + '/train'\n",
    "VAL_DIR = DATA_DIR + '/valid'\n",
    "TEST_DIR = DATA_DIR + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the validation directories\n",
    "os.mkdir(VAL_PATH)\n",
    "for i in xrange(10):\n",
    "    os.mkdir(VAL_PATH + '/c' + str(i))\n",
    "\n",
    "# # another way to do this:\n",
    "# %mkdir $VAL_PATH\n",
    "# for i in xrange(10):\n",
    "#     %mkdir $VAL_PATH/c\"$i\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run this if you don't have an Accurate Validation Set\n",
    "\n",
    "Grab a random permutation from the training data for validation. Do this until validation accuracy matches test accuracy. Also see: http://stackoverflow.com/questions/2632205/how-to-count-the-number-of-files-in-a-directory-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %cd $TRAIN_PATH\n",
    "\n",
    "# VAL_PORTION = 0.2\n",
    "# for i in xrange(10):\n",
    "#     %cd c\"$i\"\n",
    "#     g = glob('*.jpg')\n",
    "#     number = len(g)\n",
    "#     shuff = np.random.permutation(g)\n",
    "#     for n in xrange(int(number * VAL_PORTION)):\n",
    "#         os.rename(shuff[n], VAL_PATH + '/c' + str(i) + '/' + shuff[n])\n",
    "#     % cd ..\n",
    "\n",
    "def reset_valid():\n",
    "    \"\"\"Moves all images in validation set back to \n",
    "    their respective classes in the training set.\"\"\"\n",
    "    for i in xrange(10):\n",
    "        %mv $VALID_DIR/c\"$i\"/*.jpg $TRAIN_DIR/c\"$i\"/*.jpg\n",
    "\n",
    "# modified from: http://forums.fast.ai/t/statefarm-kaggle-comp/183/20\n",
    "def set_valid(number=1):\n",
    "    if number < 0: number = 0\n",
    "    for n in xrange(number):\n",
    "        # read CSV file into Pandas DataFrame\n",
    "        dil = pd.read_csv(data_path + 'driver_imgs_list.csv')\n",
    "        # group frame by subject in image\n",
    "        grouped_subjects = dil.groupby('subject')\n",
    "        # pick <number> subjects at random\n",
    "        subject = groups.keys()[np.random.randint(0, high=len(groups))] # <-- groups?\n",
    "        # get the group assoc w/ subject\n",
    "        group = grouped.get_group(subject)\n",
    "        # loop over gropu & move imgs to validation dir\n",
    "        for (subject, clssnm, img) in group.values:\n",
    "            source = '{}train/{}/{}'.format(data_path, clssnm, img)\n",
    "            target = source.replace('trian', 'valid')\n",
    "            print('mv {} {}'.format(source, target))\n",
    "            os.rename(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some more setup\n",
    "data_path    = DATA_DIR  + '/'\n",
    "train_path   = TRAIN_DIR + '/'\n",
    "valid_path   = VAL_DIR   + '/'\n",
    "test_path    = TEST_DIR  + '/'\n",
    "results_path = DATA_DIR  + '/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# looks like batch size of 64 is just past what my GPU can handle\n",
    "# would using bcolz to save precomputed arrays help?\n",
    "batch_size=48\n",
    "target_size=(224,224) # for gen.flow_from_directory(..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17943 images belonging to 10 classes.\n",
      "Found 4481 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# batch generator to feed data into the model\n",
    "gen = image.ImageDataGenerator()\n",
    "trn_batches = gen.flow_from_directory(train_path, target_size=target_size,\n",
    "                class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "val_batches = gen.flow_from_directory(valid_path, target_size=target_size,\n",
    "                class_mode='categorical', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17943"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_batches.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: I'll want a way to clear GPU memory in the future. Right now all I know is restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the VGG model, download its weights, and finetune it to the data\n",
    "VGG = Vgg16()\n",
    "VGG.model.pop()\n",
    "for layer in VGG.model.layers: layer.trainable = False\n",
    "VGG.model.add(Dense(10, activation='softmax'))\n",
    "VGG.model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "17943/17943 [==============================] - 1129s - loss: 1.9142 - acc: 0.4646 - val_loss: 0.5363 - val_acc: 0.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5febebd3d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the model until it overfits\n",
    "VGG.model.optimizer.lr = 0.001\n",
    "VGG.model.fit_generator(trn_batches, trn_batches.n, nb_epoch=1, verbose=1,\n",
    "                       validation_data=val_batches, nb_val_samples=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(lr=0.001, epochs=1, verbose=0):\n",
    "    VGG.model.optimizer.lr=lr\n",
    "    VGG.model.fit_generator(trn_batches, trn_batches.n, nb_epoch=epochs, verbose=verbose,\n",
    "                           validation_data=val_batches, nb_val_samples=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model(lr=0.1, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving weights\n",
    "VGG.model.save_weights(data_path + 'finetune01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG.model.load_weights(data_path + 'finetune01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, batch_size=4, class_mode='categorical',\n",
    "                target_size=(224,224)):\n",
    "    return gen.flow_from_directory(dirname, target_size=target_size,\n",
    "            class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)\n",
    "\n",
    "def get_data(path, target_size=(224,224)):\n",
    "    batches = get_batches(path, shuffle=False, batch_size=1, class_mode=None, target_size=target_size)\n",
    "    return np.concatenate([batches.next() for i in xrange(batches.nb_sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# output test data predictions\n",
    "gen = image.ImageDataGenerator()\n",
    "tst_batches = gen.flow_from_directory(test_path, target_size=target_size,\n",
    "                class_mode='categorical', shuffle=False, batch_size=batch_size*2)\n",
    "# predictions = VGG.model.predict_on_batch(tst_batches)\n",
    "# predictions = VGG.model.predict(tst_batches, batch_size=batch_size*2, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79726"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_batches.n\n",
    "tst_batches.nb_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "predictions = VGG.test(test_path, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(results_path + 'raw_predictions01.bc', predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79726"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79726, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = tst_batches.filenames\n",
    "# ids = np.array([str(f[8:f.find('.')]) for f in filenames])\n",
    "ids = np.array([str(f[8:]) for f in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79726,)\n",
      "(79726, 10)\n"
     ]
    }
   ],
   "source": [
    "print(ids.shape)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submissions = np.stack([ids, preds], axis=1)\n",
    "\n",
    "# couldn't get the older method of using np.stack to work, so trying pandas\n",
    "classes = sorted(trn_batches.class_indices, key=trn_batches.class_indices.get)\n",
    "submission = pd.DataFrame(preds, columns=classes)\n",
    "# submission.insert(0, 'img', [f[12:] for f in filenames])\n",
    "submission.insert(0, 'img', [f[8:] for f in filenames])\n",
    "submission.head()\n",
    "submission.to_csv(results_path + 'submission.csv', index=False, compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ??pd.DataFrame.to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/home/wnixalo/Kaukasos/FAI/lesson3/data/results/submission.csv' target='_blank'>/home/wnixalo/Kaukasos/FAI/lesson3/data/results/submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/wnixalo/Kaukasos/FAI/lesson3/data/results/submission.csv"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(results_path + 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `submission.insert` not found.\n"
     ]
    }
   ],
   "source": [
    "??submission.insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
