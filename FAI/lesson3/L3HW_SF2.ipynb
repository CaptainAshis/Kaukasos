{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New 'clean-pass' of L3HW-SF ~ usin' lessons learned\n",
    "\n",
    "Wayne Nixalo - 2017-May-23 02:37\n",
    "\n",
    "useful links:\n",
    "DataAugmentation:\n",
    "https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson3.ipynb\n",
    "\n",
    "I forgot but reference anyway:\n",
    "https://github.com/fastai/courses/blob/master/deeplearning1/nbs/lesson2.ipynb\n",
    "\n",
    "Good followthru of lecture & how to save to submission w/ Pandas:\n",
    "https://github.com/philippbayer/cats_dogs_redux/blob/master/Statefarm.ipynb\n",
    "\n",
    "Me:\n",
    "https://github.com/WNoxchi/Kaukasos/blob/master/FAI/lesson3/L3HW_SF.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import bcolz\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "sys.path.insert(1, os.path.join(os.getcwd(), '../utils'))\n",
    "import utils\n",
    "from vgg16bn import Vgg16BN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOME_DIR  = os.getcwd()\n",
    "DATA_DIR  = HOME_DIR + '/data'\n",
    "TEST_DIR  = DATA_DIR + '/test'\n",
    "TRAIN_DIR = DATA_DIR + '/train'\n",
    "VALID_DIR = DATA_DIR + '/valid'\n",
    "\n",
    "data_path    = DATA_DIR  + '/'\n",
    "test_path    = TEST_DIR  + '/'\n",
    "train_path   = TRAIN_DIR + '/'\n",
    "valid_path   = VALID_DIR + '/'\n",
    "results_path = DATA_DIR  + '/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]\n",
    "\n",
    "def reset_valid(verbose=1):\n",
    "    \"\"\"Moves all images in validation set back to \n",
    "    their respective classes in the training set.\"\"\"\n",
    "    counter = 0\n",
    "    %cd $valid_path\n",
    "    for i in xrange(10):\n",
    "        %cd c\"$i\"\n",
    "        g = glob('*.jpg')\n",
    "        for n in xrange(len(g)):\n",
    "            os.rename(g[n], TRAIN_DIR + '/c/' + str(i) + '/' + g[n])\n",
    "            counter += 1\n",
    "        %cd ..\n",
    "    if verbose: print(\"Moved {} files\".format(counter))\n",
    "\n",
    "# modified from: http://forums.fast.ai/t/statefarm-kaggle-comp/183/20\n",
    "def set_valid(number=1, verbose=1):\n",
    "    \"\"\"Moves <number> subjects from training to validation \n",
    "    directories. Verbosity 0: Silent; 1: print no. files moved;\n",
    "    2: print each move operation. Default=1\"\"\"\n",
    "    counter = 0\n",
    "    if number < 0: number = 0\n",
    "    # repeat for <number> subjects\n",
    "    for n in xrange(number):\n",
    "        # read CSV file into Pandas DataFrame\n",
    "        dil = pd.read_csv(data_path + 'driver_imgs_list.csv')\n",
    "        # grouped frame by subject in image\n",
    "        grouped_subjects = dil.groupby('subject')\n",
    "        # pick subject at random\n",
    "        subject = grouped_subjects.groups.keys()[np.random.randin(0, \\\n",
    "                                         high=len(grouped_subjects.groups))]\n",
    "        # get group assoc w/ subject\n",
    "        group = grouped_subjects.get_group(subject)\n",
    "        # loop over group & move imgs to validation dir\n",
    "        for (subject, clssnm, img) in group.values:\n",
    "            source = '{}train/{}/{}'.format(data_path, clssnm, img)\n",
    "            target = source.replace('train', 'valid')\n",
    "            if verbose > 1: print('mv {} {}'.format(source, target))\n",
    "            os.rename(source, target)\n",
    "        verbose: print(\"Files moved: {}\".format(counter))\n",
    "            \n",
    "# function to build FCNet w/ BatchNormalization & Dropout\n",
    "def create_FCbn_layers(p=0):\n",
    "    return [\n",
    "            MaxPooling2D(input_shape=Conv_model[-1].output_shape[1:]),\n",
    "            Flatten(),\n",
    "            BatchNormalization(),\n",
    "            Dense(4096, activation='relu'),\n",
    "            Dropout(p),\n",
    "            Dense(10, activation='softmax')\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating validation directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.mkdir(VAL_DIR)\n",
    "# for i in xrange(10):\n",
    "#     os.mkdir(VAL_DIR + '/c' + str(i))\n",
    "\n",
    "# # # another way to do this:\n",
    "# # %mkdir $VAL_DIR\n",
    "# # for i in xrange(10):\n",
    "# #     %mkdir $VAL_DIR/c\"$i\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting/resetting validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_valid()\n",
    "set_valid(number=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/valid batch generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.05, \n",
    "        height_shift_range=0.05, width_zoom_range=0.1, zoom_range=0.1,\n",
    "        shear_range=0.1, channel_shift_range=10)\n",
    "# does it matter that I don't set dim_ordering='tf'?\n",
    "trn_batches = gen.flow_from_directory(train_path, target_size=target_size, \n",
    "                batch_size=batch_size, shuffle=True, class_mode='categorical')\n",
    "val_batches = gen.flow_from_directory(valid_path, target_size=target_size, \n",
    "                batch_size=batch_size, shuffle=False, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load VGG16BN model & its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGGbn = Vgg16BN()\n",
    "VGGbn.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model at low η to adjust Conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find out how many epochs at what η to do this until optimal\n",
    "VGGbn.fit_generator(trn_batches, trn_batches.n, nb_epoch=1, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Conv layers & create new ConvNet (w/ vgg weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_conv_idx = [index, for index, layer in enumerate(VGGbn.model.layers) \\\n",
    "                                            if type(layer) is Convolution2D][-1]\n",
    "Conv_layers = VGGbn.model.layers[:last_conv_idx + 1]\n",
    "Conv_model = Sequential(Conv_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training batches have to be set to not be shuffled. Since the full-model is in two stages, classes & labels will be supplied to the FCNet via the batches-generator; if these are shuffled they won't match up with the output features from the ConvNet. I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_batches = gen.flow_from_directory(train_path, target_size=target_size, \n",
    "                batch_size=batch_size, shuffle=False, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Conv Model on trn/val batches to create features as inputs to FCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_features = Conv_model.predict_generator(trn_batches, trn_batches.nb_sample)\n",
    "conv_val_feat = Conv_model.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optional: save the convolutional model's output features\n",
    "# save_array(results_path + 'conv_features.dat', conv_features)\n",
    "# save_array(results_path + 'conv_val_feat.dat', conv_val_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Fully-Connected Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FC_model = Sequential(create_FCbn_layers(p=0.3))\n",
    "FC_model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train FCNet on ConvNet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FC_model.fit(conv_features, trn_batches.labels, batch_size=batch_size, \n",
    "             nb_epoch=1, validation_data=(conv_val_feat, val_batches.labels))\n",
    "# is there a way to do this as a generator -- or does it not matter?\n",
    "# maybe save the features, then pull them from disk in batches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Augmented batch generator for test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGeneratro()\n",
    "tst_batches = gen.flow_from_directory(test_path, batch_size=batch_size,\n",
    "                                      shuffle=False, class_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run test batches through ConvNet, run ConvNet test features through FCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_tst_feat = Conv_model.predict_generator(tst_batches, tst_batches.nb_sample)\n",
    "preds = FC_model.predict(conv_tst_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = tst_batches.filenames\n",
    "classes = sorted(trn_batches.class_indices, key=trn_batches.class_indices.get)\n",
    "submission = pd.DataFrame(preds, columns=classes)\n",
    "submission.insert(0, 'img', [f[8:] for f in filenames])\n",
    "submission.head()\n",
    "submission.to_csv(results_path + 'submission.csv', index=False, compression=None)\n",
    "\n",
    "from IPython.display import FileLink\n",
    "FileLink(results_path + 'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above is working:\n",
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
