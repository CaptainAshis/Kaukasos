{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wayne Nixalo - 25 Jun 2017\n",
    "\n",
    "RNN practice in Theano -- 3rd attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "%matplotlib inline\n",
    "import sys, os\n",
    "sys.path.insert(1, os.path.join('../utils'))\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 86\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars) + 1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")\n",
    "# ''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "# the 1st 10 characters:\n",
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs = 3\n",
    "# c1_dat = [idx[i] for i in xrange(0, len(idx)-1-cs, cs)]\n",
    "# c2_dat = [idx[i+1] for i in xrange(0, len(idx)-1-cs, cs)]\n",
    "# c3_dat = [idx[i+2] for i in xrange(0, len(idx)-1-cs, cs)]\n",
    "# c4_dat = [idx[i+3] for i in xrange(0, len(idx)-1-cs, cs)] # <-- gonna predict this\n",
    "\n",
    "# # we can turn these into Numpy arrays just by stacking them up together\n",
    "# x1 = np.stack(c1_dat[:-2]) # 1st chars\n",
    "# x2 = np.stack(c2_dat[:-2]) # 2nd chars\n",
    "# x3 = np.stack(c3_dat[:-2]) # 3rd chars\n",
    "# # for every 4 character peice of this - collected works\n",
    "\n",
    "# # labels will just be the 4th characters\n",
    "# y = np.stack(c4_dat[:-2])\n",
    "\n",
    "# # 1st, 2nd, 3rd chars of text\n",
    "# print x1[:4], x2[:4], x3[:4]\n",
    "\n",
    "# # 4th char of text\n",
    "# print y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # we're going to turn these into embeddings\n",
    "# n_fac = 42\n",
    "# # by creating an embedding matrix\n",
    "# def embedding_input(name, n_in, n_out):\n",
    "#     inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "#     emb = Embedding(n_in, n_out, input_length=1)(inp)\n",
    "#     return inp, Flatten()(emb)\n",
    "\n",
    "# c1_in, c1 = embedding_input('c1', vocab_size, n_fac)\n",
    "# c2_in, c2 = embedding_input('c2', vocab_size, n_fac)\n",
    "# c3_in, c3 = embedding_input('c3', vocab_size, n_fac)\n",
    "# # c1, c2, c3 represent result of putting each char through the embedding & \n",
    "# # getting out 42 latent vectors. <-- those are input to greenarrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_hidden = 256\n",
    "# dense_in = Dense(n_hidden, activation='relu')\n",
    "# c1_hidden = dense_in(c1)\n",
    "# dense_hidden = Dense(n_hidden, activation='tanh')\n",
    "\n",
    "# c2_dense = dense_in(c2) # char-2 embedding thru greenarrow\n",
    "# hidden_2 = dense_hidden(c1_hidden) # output of char-1's hidden state thru orangearrow\n",
    "# c2_hidden = merge([c2_dense, hidden_2]) # merge the two together (default: sum)\n",
    "\n",
    "# c3_dense = dense_in(c3)\n",
    "# hidden_3 = dense_hidden(c2_hidden)\n",
    "# c3_hidden = merge([c3_dense, hidden_3])\n",
    "\n",
    "# dense_out = Dense(vocab_size, activation='softmax') #output size: 86 <-- vocab_size\n",
    "\n",
    "# c4_out = dense_out(c3_hidden)\n",
    "\n",
    "# # passing in our 3 inputs & 1 output\n",
    "# model = Model([c1_in, c2_in, c3_in], c4_out)\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "# model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# THEANO RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8, 86), (75110, 8, 86))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = 8 # use 8 characters to predict the 9th\n",
    "\n",
    "c_in_dat = [[idx[i+n] for i in xrange(0, len(idx)-1-cs, cs)] for n in range(cs)]\n",
    "xs = [np.stack(c[:-2]) for c in c_in_dat]\n",
    "\n",
    "c_out_dat = [[idx[i+n] for i in xrange(1, len(idx)-cs, cs)] for n in range(cs)]\n",
    "ys = [np.stack(c[:-2]) for c in c_out_dat]\n",
    "\n",
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn = np.stack(oh_ys, axis=1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn = np.stack(oh_xs, axis=1)\n",
    "\n",
    "oh_x_rnn.shape, oh_y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WayNoxchi/Miniconda3/Theano/theano/tensor/basic.py:5130: UserWarning: flatten outdim parameter is deprecated, use ndim instead.\n",
      "  \"flatten outdim parameter is deprecated, use ndim instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:25.145\n",
      "Error:21.382\n",
      "Error:20.902\n",
      "Error:19.896\n",
      "Error:18.812\n",
      "Error:19.244\n",
      "Error:19.097\n",
      "Error:18.494\n",
      "Error:17.925\n",
      "Error:18.202\n",
      "Error:17.502\n",
      "Error:17.615\n",
      "Error:18.461\n",
      "Error:17.315\n",
      "Error:16.782\n",
      "Error:17.773\n",
      "Error:17.333\n",
      "Error:17.251\n",
      "Error:16.822\n",
      "Error:16.706\n",
      "Error:16.546\n",
      "Error:16.386\n",
      "Error:16.727\n",
      "Error:16.118\n",
      "Error:16.795\n",
      "Error:16.591\n",
      "Error:16.019\n",
      "Error:16.326\n",
      "Error:16.223\n",
      "Error:16.511\n",
      "Error:16.686\n",
      "Error:16.429\n",
      "Error:16.664\n",
      "Error:16.291\n",
      "Error:16.009\n",
      "Error:16.672\n",
      "Error:15.998\n",
      "Error:16.431\n",
      "Error:16.081\n",
      "Error:16.268\n",
      "Error:15.323\n",
      "Error:15.704\n",
      "Error:15.754\n",
      "Error:15.956\n",
      "Error:15.917\n",
      "Error:15.858\n",
      "Error:15.637\n",
      "Error:16.027\n",
      "Error:16.016\n",
      "Error:16.037\n",
      "Error:15.219\n",
      "Error:15.571\n",
      "Error:15.002\n",
      "Error:14.894\n",
      "Error:15.676\n",
      "Error:15.402\n",
      "Error:14.696\n",
      "Error:15.468\n",
      "Error:15.095\n",
      "Error:15.011\n",
      "Error:15.033\n",
      "Error:15.527\n",
      "Error:15.278\n",
      "Error:15.077\n",
      "Error:14.729\n",
      "Error:14.817\n",
      "Error:14.281\n",
      "Error:14.751\n",
      "Error:15.191\n",
      "Error:14.712\n",
      "Error:15.226\n",
      "Error:14.772\n",
      "Error:14.493\n",
      "Error:14.514\n",
      "Error:14.471\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 256; n_fac = 42; cs = 8\n",
    "\n",
    "n_input = vocab_size\n",
    "n_output = vocab_size\n",
    "\n",
    "def init_wgts(rows, cols): \n",
    "    scale = math.sqrt(2/rows) # 1st calc Glorot number to scale weights\n",
    "    return shared(normal(scale=scale, size=(rows, cols)).astype(np.float32))\n",
    "def init_bias(rows): \n",
    "    return shared(np.zeros(rows, dtype=np.float32))\n",
    "def wgts_and_bias(n_in, n_out): \n",
    "    return init_wgts(n_in, n_out), init_bias(n_out)\n",
    "def id_and_bias(n): \n",
    "    return shared(np.eye(n, dtype=np.float32)), init_bias(n)\n",
    "\n",
    "# Theano variables\n",
    "t_inp = T.matrix('inp')\n",
    "t_outp = T.matrix('outp')\n",
    "t_h0 = T.vector('h0')\n",
    "lr = T.scalar('lr')\n",
    "\n",
    "all_args = [t_h0, t_inp, t_outp, lr]\n",
    "\n",
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = wgts_and_bias(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W_h, W_x, W_y]))\n",
    "\n",
    "def step(x, h, W_h, b_h, W_x, b_x, W_y, b_y):\n",
    "    # Calculate the hidden activations\n",
    "    h = nnet.relu(T.dot(x, W_x) + b_x + T.dot(h, W_h) + b_h)\n",
    "    # Calculate the output activations\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    # Return both (the 'Flatten()' is to work around a theano bug)\n",
    "    return h, T.flatten(y, 1)\n",
    "\n",
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp,\n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)\n",
    "\n",
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)\n",
    "\n",
    "def upd_dict(wgts, grads, lr):\n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts,grads)})\n",
    "\n",
    "upd = upd_dict(w_all, g_all, lr)\n",
    "\n",
    "# we're finally ready to compile the function!:\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)\n",
    "\n",
    "X = oh_x_rnn\n",
    "Y = oh_y_rnn\n",
    "X.shape, Y.shape\n",
    "\n",
    "err=0.0; l_rate=0.01\n",
    "for i in xrange(len(X)):\n",
    "    err += fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999:\n",
    "        print (\"Error:{:.3f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_y = theano.function([t_h0, t_inp], v_y, allow_input_downcast=True)\n",
    "\n",
    "pred = np.argmax(f_y(np.zeros(n_hidden), X[6]), axis=1)\n",
    "\n",
    "act = np.argmax(X[6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 'n', '?', ' ', 'I', 's']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[o] for o in act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'e', ' ', ' ', ' ', 'T', 't', ' ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[o] for o in pred]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
