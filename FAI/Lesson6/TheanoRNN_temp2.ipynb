{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('corpus length:', 600901)\n",
      "('total chars:', 86)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([40,  1, 33,  2, 72, 67, 73,  2]),\n",
       " array([42,  1, 38, 44,  2,  9, 61, 73]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import theano\n",
    "import sys, os\n",
    "sys.path.insert(1, os.path.join('../utils'))\n",
    "from utils import *\n",
    "\n",
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars) + 1\n",
    "print('total chars:', vocab_size)\n",
    "\n",
    "chars.insert(0, \"\\0\")\n",
    "\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "n_fac = 42\n",
    "n_hidden = 256\n",
    "cs = 8\n",
    "\n",
    "c_in_dat = [[idx[i+n] for i in xrange(0, len(idx)-1-cs, cs)] for n in range(cs)]\n",
    "# c_out_dat = [[idx[i+n] for i in xrange(1, len(idx)-cs, cs)] for n in range(cs)]\n",
    "\n",
    "xs = [np.stack(c[:-2]) for c in c_in_dat]\n",
    "ys = [np.stack(c[:-2]) for c in c_out_dat]\n",
    "\n",
    "# before model fit\n",
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [idx[i+cs] for i in xrange(0, len(idx)-1-cs,cs)]\n",
    "y = np.stack(c_out_dat[:-2])\n",
    "\n",
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name+'_in')\n",
    "    emb = Embedding(n_in, n_out, input_length=1, name=name+'_emb')(inp)\n",
    "    return inp, Flatten()(emb)\n",
    "\n",
    "c_ins = [embedding_input('c'+str(n), vocab_size, n_fac) for n in range(cs)]\n",
    "n_hidden = 256\n",
    "\n",
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "dense_hidden = Dense(n_hidden, activation='relu', init='identity')\n",
    "dense_out = Dense(vocab_size, activation='softmax')\n",
    "\n",
    "hidden = dense_in(c_ins[0][1])\n",
    "\n",
    "for i in range(1,cs):\n",
    "    c_dense = dense_in(c_ins[i][1]) #green arrow\n",
    "    hidden = dense_hidden(hidden)   #orange arrow\n",
    "    hidden = merge([c_dense, hidden]) #merge the two together\n",
    "    \n",
    "    c_out = dense_out(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "75110/75110 [==============================] - 7s - loss: 2.5326     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11aee2490>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model([c[0] for c in c_ins], c_out)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "model.fit(xs, y, batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[40],\n",
       "        [ 1],\n",
       "        [33],\n",
       "        [ 2],\n",
       "        [72],\n",
       "        [67],\n",
       "        [73],\n",
       "        [ 2]]), array([[42],\n",
       "        [ 1],\n",
       "        [38],\n",
       "        [44],\n",
       "        [ 2],\n",
       "        [ 9],\n",
       "        [61],\n",
       "        [73]]), array([[29],\n",
       "        [43],\n",
       "        [31],\n",
       "        [71],\n",
       "        [54],\n",
       "        [ 9],\n",
       "        [58],\n",
       "        [61]]), array([[30],\n",
       "        [45],\n",
       "        [ 2],\n",
       "        [74],\n",
       "        [ 2],\n",
       "        [76],\n",
       "        [67],\n",
       "        [58]]), array([[25],\n",
       "        [40],\n",
       "        [73],\n",
       "        [73],\n",
       "        [76],\n",
       "        [61],\n",
       "        [24],\n",
       "        [71]]), array([[27],\n",
       "        [40],\n",
       "        [61],\n",
       "        [61],\n",
       "        [68],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [58]]), array([[29],\n",
       "        [39],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [66],\n",
       "        [73],\n",
       "        [33],\n",
       "        [ 2]]), array([[ 1],\n",
       "        [43],\n",
       "        [73],\n",
       "        [62],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [72],\n",
       "        [67]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after model fit\n",
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8, 86), (75110, 8, 86))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_out_dat = [[idx[i+n] for i in xrange(1, len(idx)-cs, cs)] for n in range(cs)]\n",
    "ys = [np.stack(c[:-2]) for c in c_out_dat]\n",
    "\n",
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn = np.stack(oh_ys, axis=1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn = np.stack(oh_xs, axis=1)\n",
    "\n",
    "oh_x_rnn.shape, oh_y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WayNoxchi/Miniconda3/Theano/theano/tensor/basic.py:5130: UserWarning: flatten outdim parameter is deprecated, use ndim instead.\n",
      "  \"flatten outdim parameter is deprecated, use ndim instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75110, 8, 86) (75110, 8, 86)\n",
      "ErrorX:28.986\n",
      "ErrorX:25.977\n",
      "ErrorX:25.761\n",
      "ErrorX:25.518\n",
      "ErrorX:25.341\n",
      "ErrorX:25.490\n",
      "ErrorX:25.177\n",
      "ErrorX:25.101\n",
      "ErrorX:25.151\n",
      "ErrorX:25.495\n",
      "ErrorX:24.801\n",
      "ErrorX:25.009\n",
      "ErrorX:26.446\n",
      "ErrorX:25.014\n",
      "ErrorX:24.888\n",
      "ErrorX:26.046\n",
      "ErrorX:25.932\n",
      "ErrorX:25.714\n",
      "ErrorX:25.041\n",
      "ErrorX:24.938\n",
      "ErrorX:24.872\n",
      "ErrorX:25.092\n",
      "ErrorX:25.351\n",
      "ErrorX:24.953\n",
      "ErrorX:25.128\n",
      "ErrorX:25.144\n",
      "ErrorX:25.317\n",
      "ErrorX:24.996\n",
      "ErrorX:25.114\n",
      "ErrorX:25.300\n",
      "ErrorX:25.438\n",
      "ErrorX:25.180\n",
      "ErrorX:25.548\n",
      "ErrorX:25.050\n",
      "ErrorX:25.253\n",
      "ErrorX:25.591\n",
      "ErrorX:25.060\n",
      "ErrorX:25.380\n",
      "ErrorX:25.277\n",
      "ErrorX:25.589\n",
      "ErrorX:24.948\n",
      "ErrorX:24.953\n",
      "ErrorX:25.200\n",
      "ErrorX:25.384\n",
      "ErrorX:25.643\n",
      "ErrorX:25.679\n",
      "ErrorX:25.149\n",
      "ErrorX:24.073\n",
      "ErrorX:24.635\n",
      "ErrorX:24.867\n",
      "ErrorX:24.429\n",
      "ErrorX:24.570\n",
      "ErrorX:24.357\n",
      "ErrorX:24.355\n",
      "ErrorX:24.773\n",
      "ErrorX:24.590\n",
      "ErrorX:24.631\n",
      "ErrorX:24.551\n",
      "ErrorX:24.523\n",
      "ErrorX:24.688\n",
      "ErrorX:24.431\n",
      "ErrorX:24.619\n",
      "ErrorX:24.658\n",
      "ErrorX:24.774\n",
      "ErrorX:24.477\n",
      "ErrorX:24.342\n",
      "ErrorX:24.341\n",
      "ErrorX:24.398\n",
      "ErrorX:24.153\n",
      "ErrorX:24.214\n",
      "ErrorX:24.885\n",
      "ErrorX:24.407\n",
      "ErrorX:24.177\n",
      "ErrorX:24.022\n",
      "ErrorX:23.951\n"
     ]
    }
   ],
   "source": [
    "# THEANO RNN\n",
    "\n",
    "n_input = vocab_size\n",
    "n_output = vocab_size\n",
    "\n",
    "def init_wgts(rows, cols):\n",
    "    scale = math.sqrt(2/rows)\n",
    "    return shared(normal(scale=scale, size=(rows,cols)).astype(np.float32))\n",
    "def init_bias(rows):\n",
    "    return shared(np.zeros(rows, dtype=np.float32))\n",
    "def wgts_and_bias(n_in, n_out):\n",
    "    return init_wgts(n_in, n_out), init_bias(n_out)\n",
    "def id_and_bias(n):\n",
    "    return shared(np.eye(n, dtype=np.float32)), init_bias(n)\n",
    "\n",
    "# Theano Variables\n",
    "t_inp = T.matrix('inp')\n",
    "t_outp = T.matrix('outp')\n",
    "t_h0 = T.vector('h0')\n",
    "lr = T.scalar('lr')\n",
    "\n",
    "all_args = [t_h0, t_inp, t_outp, lr]\n",
    "\n",
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = wgts_and_bias(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W_h, W_x, W_y]))\n",
    "\n",
    "def step(x, h, W_h, b_h, W_x, b_x, W_y, b_y):\n",
    "    # Calculate the hidden activations\n",
    "    h = nnet.relu(T.dot(x, W_x) + b_x + T.dot(h, W_h) + b_h)\n",
    "    # Calculate the output activations\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    # Return both (the `Flatten()` is to work around a Theano bug)\n",
    "    return h, T.flatten(y, 1)\n",
    "\n",
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp,\n",
    "                             outputs_info=[t_h0, None], non_sequences=w_all)\n",
    "\n",
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)\n",
    "\n",
    "def upd_dict(wgts, grads, lr):\n",
    "    return OrderedDict({w: w - g * lr for (w,g) in zip(wgts, grads)})\n",
    "\n",
    "upd = upd_dict(w_all, g_all, lr)\n",
    "\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)\n",
    "\n",
    "X = oh_x_rnn\n",
    "Y = oh_y_rnn\n",
    "print X.shape, Y.shape\n",
    "\n",
    "err = 0.0; l_rate = 0.01\n",
    "for i in xrange(len(X)):\n",
    "    err += fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999:\n",
    "        print (\"ErrorX:{:.3f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, thoroughly lost.. Need to go back through the lesson 6 notebook.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
